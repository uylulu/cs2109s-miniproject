{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9796ccee",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "94c16068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asset root for rendering. You can change this if you want to use custom game assets.\n",
    "ASSET_ROOT = \"../data/assets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4b7e1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendering and display\n",
    "from grid_universe.renderer.texture import TextureRenderer\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "10d7217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default renderer used throughout the notebook unless overridden in a cell\n",
    "renderer = TextureRenderer(resolution=240, asset_root=ASSET_ROOT)\n",
    "renderer_large = TextureRenderer(resolution=480, asset_root=ASSET_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "cfe4826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from typing import List\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "133f4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSPIRED BY VGG16 architecture\n",
    "def get_model(num_classes: int) -> nn.Module:\n",
    "    res = nn.Sequential(\n",
    "        nn.Conv2d(3, 8, kernel_size=3, padding=1),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.BatchNorm2d(8),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.MaxPool2d(2),\n",
    "\n",
    "        nn.Flatten(),\n",
    "\n",
    "        nn.Linear(3136, 70),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(70, num_classes)\n",
    "    )\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36784cb",
   "metadata": {},
   "source": [
    "### The augmentation needs to randomly draw the directional triangle into the picture classes where there could be a direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "51c2d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def draw_direction_triangles_on_image(\n",
    "    image: Image.Image, size: int, dx: int, dy: int, count: int\n",
    ") -> Image.Image:\n",
    "    \"\"\"\n",
    "    Draw 'count' filled triangles pointing (dx, dy) on the given RGBA image.\n",
    "    Triangles are centered: the centroid of each triangle is symmetrically arranged\n",
    "    around the image center. Spacing is between triangle centroids.\n",
    "    \"\"\"\n",
    "    if count <= 0 or (dx, dy) == (0, 0):\n",
    "        return image\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    cx, cy = size // 2, size // 2\n",
    "\n",
    "    # Triangle geometry (relative to size)\n",
    "    tri_height = max(4, int(size * 0.16))\n",
    "    tri_half_base = max(3, int(size * 0.10))\n",
    "    spacing = max(2, int(size * 0.12))  # distance between triangle centroids\n",
    "\n",
    "    # Axis-aligned direction and perpendicular\n",
    "    ux, uy = dx, dy  # points toward the triangle tip\n",
    "    px, py = -uy, ux  # perpendicular (for base width)\n",
    "\n",
    "    # Offsets for centroids: 1 -> [0], 2 -> [-0.5s, +0.5s], 3 -> [-s, 0, +s], ...\n",
    "    offsets = [(i - (count - 1) / 2.0) * spacing for i in range(count)]\n",
    "\n",
    "    # For an isosceles triangle, the centroid lies 1/3 of the height from the base toward the tip.\n",
    "    # If C is the centroid, then:\n",
    "    #   tip = C + (2/3)*tri_height * u\n",
    "    #   base_center = C - (1/3)*tri_height * u\n",
    "    tip_offset = (2.0 / 3.0) * tri_height\n",
    "    base_offset = (1.0 / 3.0) * tri_height\n",
    "\n",
    "    for off in offsets:\n",
    "        # Centroid position\n",
    "        Cx = cx + int(round(ux * off))\n",
    "        Cy = cy + int(round(uy * off))\n",
    "\n",
    "        # Tip and base-center positions\n",
    "        tip_x = int(round(Cx + ux * tip_offset))\n",
    "        tip_y = int(round(Cy + uy * tip_offset))\n",
    "        base_x = int(round(Cx - ux * base_offset))\n",
    "        base_y = int(round(Cy - uy * base_offset))\n",
    "\n",
    "        # Base vertices around base center along the perpendicular\n",
    "        p1 = (tip_x, tip_y)\n",
    "        p2 = (\n",
    "            int(round(base_x + px * tri_half_base)),\n",
    "            int(round(base_y + py * tri_half_base)),\n",
    "        )\n",
    "        p3 = (\n",
    "            int(round(base_x - px * tri_half_base)),\n",
    "            int(round(base_y - py * tri_half_base)),\n",
    "        )\n",
    "\n",
    "        draw.polygon([p1, p2, p3], fill=(255, 255, 255, 220), outline=(0, 0, 0, 220))\n",
    "\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "29a74244",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['boots', 'box', 'coin', 'dragon', 'exit', 'floor', 'gem', 'ghost', 'human', 'key', 'lava', 'locked', 'metalbox', 'opened', 'portal', 'robot', 'shield', 'sleeping', 'spike', 'wall', 'wolf', 'dragon']\n",
    "\n",
    "class RandomDirection:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, image: Image.Image, label: int):\n",
    "        if labels[label] == 'box' or labels[label] == 'metalbox' or labels[label] == 'robot':\n",
    "            directions = [(1, 0), (-1, 0), (0, 1), (0, -1)]\n",
    "            random.seed(time.time())\n",
    "            decision = random.randint(-1, 3)\n",
    "\n",
    "            if decision < 0:\n",
    "                return image\n",
    "\n",
    "            dx, dy = directions[decision]\n",
    "            new_image: Image.Image = draw_direction_triangles_on_image(image=image, size=image.size[0], dx=dx, dy=dy, count=1)       \n",
    "\n",
    "            return new_image\n",
    "        return  image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1a268974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset, transform):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.random_direction = RandomDirection()\n",
    "        self.targets = base_dataset.targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.base_dataset[idx]\n",
    "        new_image: Image.Image = self.random_direction(image, label)\n",
    "        image = self.transform(new_image)\n",
    "        return image, label\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "894cf1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentations():\n",
    "    T = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(58),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    ])\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9413d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSET_DIR = \"../data/assets/imagen1\"\n",
    "\n",
    "base_dataset = ImageFolder(root=ASSET_DIR)\n",
    "dataset = CustomDataset(base_dataset, transform=get_augmentations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "567b9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = dataset.targets\n",
    "indices = list(range(len(targets)))\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=0.2,\n",
    "    stratify=targets,\n",
    "    random_state=int(time.time())\n",
    ")\n",
    "\n",
    "train_data = Subset(dataset, train_idx)\n",
    "test_data = Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a052d44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [dataset[i][1] for i in train_idx]\n",
    "test_labels = [dataset[i][1] for i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "dc77d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5374f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "    y_pred = torch.argmax(pred, dim=1).long()\n",
    "    label = label.view(-1).long() \n",
    "    return (y_pred == label).float().mean()\n",
    "\n",
    "def get_model_accuracy(model: nn.Module):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        sum_acc = 0\n",
    "        cnt = 0\n",
    "\n",
    "        for x, y in test_loader:\n",
    "            pred = model(x)\n",
    "\n",
    "            sum_acc += get_accuracy(pred, y)\n",
    "            cnt += 1\n",
    "        \n",
    "        return float(sum_acc / cnt)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "427186cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(loader: torch.utils.data.DataLoader, model: nn.Module):\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.CrossEntropyLoss()  \n",
    "\n",
    "    epoch_losses = []\n",
    "    for i in range(50):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for _, (x, y) in enumerate(loader):\n",
    "            optimiser.zero_grad()\n",
    "            # x, y = x.cuda(), y.cuda()\n",
    "            y_pred = model(x)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "        epoch_loss = epoch_loss / len(loader)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(i, epoch_loss, get_model_accuracy(model)))\n",
    "        \n",
    "\n",
    "    return model, epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d658bc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.8652151823043823, Accuracy: 0.10891088843345642\n",
      "Epoch: 1, Loss: 2.105020046234131, Accuracy: 0.1782178282737732\n",
      "Epoch: 2, Loss: 1.6250371932983398, Accuracy: 0.3465346395969391\n",
      "Epoch: 3, Loss: 1.2851938009262085, Accuracy: 0.5742574334144592\n",
      "Epoch: 4, Loss: 1.0332130193710327, Accuracy: 0.6732673048973083\n",
      "Epoch: 5, Loss: 0.8370908200740814, Accuracy: 0.6930692791938782\n",
      "Epoch: 6, Loss: 0.7628727853298187, Accuracy: 0.7029703259468079\n",
      "Epoch: 7, Loss: 0.5791459679603577, Accuracy: 0.7425742745399475\n",
      "Epoch: 8, Loss: 0.4744180589914322, Accuracy: 0.7722772359848022\n",
      "Epoch: 9, Loss: 0.37492232024669647, Accuracy: 0.8118811845779419\n",
      "Epoch: 10, Loss: 0.31579071283340454, Accuracy: 0.8316831588745117\n",
      "Epoch: 11, Loss: 0.30646124482154846, Accuracy: 0.8514851331710815\n",
      "Epoch: 12, Loss: 0.27616460621356964, Accuracy: 0.8514851331710815\n",
      "Epoch: 13, Loss: 0.22948893159627914, Accuracy: 0.8811880946159363\n",
      "Epoch: 14, Loss: 0.2030021846294403, Accuracy: 0.8811880946159363\n",
      "Epoch: 15, Loss: 0.18847127258777618, Accuracy: 0.8613861203193665\n",
      "Epoch: 16, Loss: 0.15454800426959991, Accuracy: 0.8910890817642212\n",
      "Epoch: 17, Loss: 0.1326867640018463, Accuracy: 0.8613861203193665\n",
      "Epoch: 18, Loss: 0.11490536108613014, Accuracy: 0.8910890817642212\n",
      "Epoch: 19, Loss: 0.10735141858458519, Accuracy: 0.8910890817642212\n",
      "Epoch: 20, Loss: 0.0853869840502739, Accuracy: 0.8712871074676514\n",
      "Epoch: 21, Loss: 0.08791617676615715, Accuracy: 0.8811880946159363\n",
      "Epoch: 22, Loss: 0.0640929825603962, Accuracy: 0.8910890817642212\n",
      "Epoch: 23, Loss: 0.05565491132438183, Accuracy: 0.9108911156654358\n",
      "Epoch: 24, Loss: 0.0748913399875164, Accuracy: 0.9207921028137207\n",
      "Epoch: 25, Loss: 0.060067759826779366, Accuracy: 0.9504950642585754\n",
      "Epoch: 26, Loss: 0.05590702034533024, Accuracy: 0.9702970385551453\n",
      "Epoch: 27, Loss: 0.030681855045259, Accuracy: 0.9900990128517151\n",
      "Epoch: 28, Loss: 0.041269704699516296, Accuracy: 0.9603960514068604\n",
      "Epoch: 29, Loss: 0.029289613477885723, Accuracy: 0.9801980257034302\n",
      "Epoch: 30, Loss: 0.041799839586019516, Accuracy: 0.9702970385551453\n",
      "Epoch: 31, Loss: 0.031863161362707615, Accuracy: 0.9900990128517151\n",
      "Epoch: 32, Loss: 0.05128083378076553, Accuracy: 0.9900990128517151\n",
      "Epoch: 33, Loss: 0.02822069451212883, Accuracy: 0.9900990128517151\n",
      "Epoch: 34, Loss: 0.038664656691253185, Accuracy: 0.9801980257034302\n",
      "Epoch: 35, Loss: 0.027231529355049133, Accuracy: 0.9801980257034302\n",
      "Epoch: 36, Loss: 0.024220109917223454, Accuracy: 0.9900990128517151\n",
      "Epoch: 37, Loss: 0.030687124468386173, Accuracy: 0.9702970385551453\n",
      "Epoch: 38, Loss: 0.04053386114537716, Accuracy: 1.0\n",
      "Epoch: 39, Loss: 0.032911159098148346, Accuracy: 0.9900990128517151\n",
      "Epoch: 40, Loss: 0.019657572265714407, Accuracy: 0.9702970385551453\n",
      "Epoch: 41, Loss: 0.01934821903705597, Accuracy: 0.9900990128517151\n",
      "Epoch: 42, Loss: 0.019015786238014698, Accuracy: 1.0\n",
      "Epoch: 43, Loss: 0.029721468687057495, Accuracy: 1.0\n",
      "Epoch: 44, Loss: 0.020836147479712963, Accuracy: 0.9801980257034302\n",
      "Epoch: 45, Loss: 0.015496330335736275, Accuracy: 1.0\n",
      "Epoch: 46, Loss: 0.01625149603933096, Accuracy: 0.9900990128517151\n",
      "Epoch: 47, Loss: 0.013370060361921787, Accuracy: 1.0\n",
      "Epoch: 48, Loss: 0.027694490738213062, Accuracy: 1.0\n",
      "Epoch: 49, Loss: 0.01952454447746277, Accuracy: 0.9900990128517151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (1): LeakyReLU(negative_slope=0.1)\n",
       "   (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (5): LeakyReLU(negative_slope=0.1)\n",
       "   (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (8): Flatten(start_dim=1, end_dim=-1)\n",
       "   (9): Linear(in_features=3136, out_features=70, bias=True)\n",
       "   (10): LeakyReLU(negative_slope=0.1)\n",
       "   (11): Dropout(p=0.3, inplace=False)\n",
       "   (12): Linear(in_features=70, out_features=21, bias=True)\n",
       " ),\n",
       " [2.8652151823043823,\n",
       "  2.105020046234131,\n",
       "  1.6250371932983398,\n",
       "  1.2851938009262085,\n",
       "  1.0332130193710327,\n",
       "  0.8370908200740814,\n",
       "  0.7628727853298187,\n",
       "  0.5791459679603577,\n",
       "  0.4744180589914322,\n",
       "  0.37492232024669647,\n",
       "  0.31579071283340454,\n",
       "  0.30646124482154846,\n",
       "  0.27616460621356964,\n",
       "  0.22948893159627914,\n",
       "  0.2030021846294403,\n",
       "  0.18847127258777618,\n",
       "  0.15454800426959991,\n",
       "  0.1326867640018463,\n",
       "  0.11490536108613014,\n",
       "  0.10735141858458519,\n",
       "  0.0853869840502739,\n",
       "  0.08791617676615715,\n",
       "  0.0640929825603962,\n",
       "  0.05565491132438183,\n",
       "  0.0748913399875164,\n",
       "  0.060067759826779366,\n",
       "  0.05590702034533024,\n",
       "  0.030681855045259,\n",
       "  0.041269704699516296,\n",
       "  0.029289613477885723,\n",
       "  0.041799839586019516,\n",
       "  0.031863161362707615,\n",
       "  0.05128083378076553,\n",
       "  0.02822069451212883,\n",
       "  0.038664656691253185,\n",
       "  0.027231529355049133,\n",
       "  0.024220109917223454,\n",
       "  0.030687124468386173,\n",
       "  0.04053386114537716,\n",
       "  0.032911159098148346,\n",
       "  0.019657572265714407,\n",
       "  0.01934821903705597,\n",
       "  0.019015786238014698,\n",
       "  0.029721468687057495,\n",
       "  0.020836147479712963,\n",
       "  0.015496330335736275,\n",
       "  0.01625149603933096,\n",
       "  0.013370060361921787,\n",
       "  0.027694490738213062,\n",
       "  0.01952454447746277])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(21)\n",
    "train_model(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cee52500",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"image-classification-stratified-80-20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "bae4ab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG LABEL, expected: 2, got: 17\n",
      "Total count: 4, label: 0, Accuracy: 1.0\n",
      "Total count: 4, label: 1, Accuracy: 1.0\n",
      "Total count: 5, label: 2, Accuracy: 0.8\n",
      "Total count: 5, label: 3, Accuracy: 1.0\n",
      "Total count: 5, label: 4, Accuracy: 1.0\n",
      "Total count: 5, label: 5, Accuracy: 1.0\n",
      "Total count: 5, label: 6, Accuracy: 1.0\n",
      "Total count: 5, label: 7, Accuracy: 1.0\n",
      "Total count: 6, label: 8, Accuracy: 1.0\n",
      "Total count: 5, label: 9, Accuracy: 1.0\n",
      "Total count: 5, label: 10, Accuracy: 1.0\n",
      "Total count: 4, label: 11, Accuracy: 1.0\n",
      "Total count: 4, label: 12, Accuracy: 1.0\n",
      "Total count: 5, label: 13, Accuracy: 1.0\n",
      "Total count: 5, label: 14, Accuracy: 1.0\n",
      "Total count: 5, label: 15, Accuracy: 1.0\n",
      "Total count: 4, label: 16, Accuracy: 1.0\n",
      "Total count: 5, label: 17, Accuracy: 1.0\n",
      "Total count: 4, label: 18, Accuracy: 1.0\n",
      "Total count: 5, label: 19, Accuracy: 1.0\n",
      "Total count: 6, label: 20, Accuracy: 1.0\n",
      "WRONG LABEL, expected: 2, got: 8\n",
      "Total count: 4, label: 0, Accuracy: 1.0\n",
      "Total count: 4, label: 1, Accuracy: 1.0\n",
      "Total count: 5, label: 2, Accuracy: 0.8\n",
      "Total count: 5, label: 3, Accuracy: 1.0\n",
      "Total count: 5, label: 4, Accuracy: 1.0\n",
      "Total count: 5, label: 5, Accuracy: 1.0\n",
      "Total count: 5, label: 6, Accuracy: 1.0\n",
      "Total count: 5, label: 7, Accuracy: 1.0\n",
      "Total count: 6, label: 8, Accuracy: 1.0\n",
      "Total count: 5, label: 9, Accuracy: 1.0\n",
      "Total count: 5, label: 10, Accuracy: 1.0\n",
      "Total count: 4, label: 11, Accuracy: 1.0\n",
      "Total count: 4, label: 12, Accuracy: 1.0\n",
      "Total count: 5, label: 13, Accuracy: 1.0\n",
      "Total count: 5, label: 14, Accuracy: 1.0\n",
      "Total count: 5, label: 15, Accuracy: 1.0\n",
      "Total count: 4, label: 16, Accuracy: 1.0\n",
      "Total count: 5, label: 17, Accuracy: 1.0\n",
      "Total count: 4, label: 18, Accuracy: 1.0\n",
      "Total count: 5, label: 19, Accuracy: 1.0\n",
      "Total count: 6, label: 20, Accuracy: 1.0\n",
      "Total count: 4, label: 0, Accuracy: 1.0\n",
      "Total count: 4, label: 1, Accuracy: 1.0\n",
      "Total count: 5, label: 2, Accuracy: 1.0\n",
      "Total count: 5, label: 3, Accuracy: 1.0\n",
      "Total count: 5, label: 4, Accuracy: 1.0\n",
      "Total count: 5, label: 5, Accuracy: 1.0\n",
      "Total count: 5, label: 6, Accuracy: 1.0\n",
      "Total count: 5, label: 7, Accuracy: 1.0\n",
      "Total count: 6, label: 8, Accuracy: 1.0\n",
      "Total count: 5, label: 9, Accuracy: 1.0\n",
      "Total count: 5, label: 10, Accuracy: 1.0\n",
      "Total count: 4, label: 11, Accuracy: 1.0\n",
      "Total count: 4, label: 12, Accuracy: 1.0\n",
      "Total count: 5, label: 13, Accuracy: 1.0\n",
      "Total count: 5, label: 14, Accuracy: 1.0\n",
      "Total count: 5, label: 15, Accuracy: 1.0\n",
      "Total count: 4, label: 16, Accuracy: 1.0\n",
      "Total count: 5, label: 17, Accuracy: 1.0\n",
      "Total count: 4, label: 18, Accuracy: 1.0\n",
      "Total count: 5, label: 19, Accuracy: 1.0\n",
      "Total count: 6, label: 20, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy_for_each_label(model: nn.Module):\n",
    "    for epoch in range(0, 3):\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            acc: List[int] = [0 for i in range(21)]\n",
    "            cnt: List[int] = [0 for i in range(21)]\n",
    "\n",
    "            for x, y in test_loader:\n",
    "                for label in y:\n",
    "                    cnt[label] += 1\n",
    "                \n",
    "                pred = model(x)\n",
    "                y_pred = torch.argmax(pred, dim=1).long()\n",
    "                label = y.view(-1).long()\n",
    "\n",
    "                for i in range(len(y_pred)):\n",
    "                    if y_pred[i] == label[i]:\n",
    "                        acc[label[i]] += 1\n",
    "                    else:\n",
    "                        print(\"WRONG LABEL, expected: {}, got: {}\".format(label[i], y_pred[i]))\n",
    "\n",
    "            for i in range(21):\n",
    "                print(\"Total count: {}, label: {}, Accuracy: {}\".format(cnt[i], i, float(acc[i] / cnt[i])))\n",
    "\n",
    "get_accuracy_for_each_label(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f94d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(21)\n",
    "model.load_state_dict(torch.load(\"image-classification-stratified-80-20\", weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "da8be678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoâ€‘generate a loader snippet for the trained PyTorch model\n",
    "from utils import generate_torch_loader_snippet\n",
    "\n",
    "example_input = torch.tensor(\n",
    "    [[0.0, 0.0]], dtype=torch.float32\n",
    ")  # minimal example for tracing if needed\n",
    "snippet = generate_torch_loader_snippet(\n",
    "    model=get_model(21), prefer=\"auto\"\n",
    ", compression=\"zlib\")\n",
    "\n",
    "with open(\"image_model.py\", \"w\") as f:\n",
    "    f.write(snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d8558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs2109s-ay2526s1-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
