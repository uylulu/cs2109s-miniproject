{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9796ccee",
   "metadata": {},
   "source": [
    "### Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "853a68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94c16068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asset root for rendering. You can change this if you want to use custom game assets.\n",
    "ASSET_ROOT = \"../data/assets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4b7e1ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rendering and display\n",
    "from grid_universe.renderer.texture import TextureRenderer\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "10d7217f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default renderer used throughout the notebook unless overridden in a cell\n",
    "renderer = TextureRenderer(resolution=240, asset_root=ASSET_ROOT)\n",
    "renderer_large = TextureRenderer(resolution=480, asset_root=ASSET_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cfe4826d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from typing import List\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133f4e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "### INSPIRED BY VGG16 architecture\n",
    "### WHY I USED BATCHNORM: https://towardsdatascience.com/exploring-the-superhero-role-of-2d-batch-normalization-in-deep-learning-architectures-b4eb869e8b60/\n",
    "def get_model(num_classes: int) -> nn.Module:\n",
    "    res = nn.Sequential(\n",
    "        nn.Conv2d(4, 8, kernel_size=3, padding=1),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.BatchNorm2d(8),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(8, 16, kernel_size=3, padding=1),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.BatchNorm2d(16),\n",
    "        nn.MaxPool2d(2),\n",
    "\n",
    "        nn.Flatten(),\n",
    "\n",
    "        nn.Linear(2304, 64),\n",
    "        nn.LeakyReLU(0.1),\n",
    "        nn.Linear(64, num_classes)\n",
    "    )\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36784cb",
   "metadata": {},
   "source": [
    "### The augmentation needs to randomly draw the directional triangle into the picture classes where there could be a direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c2d968",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TAKEN FROM GRID UNIVERSE LIBRARY\n",
    "def draw_direction_triangles_on_image(\n",
    "    image: Image.Image, size: int, dx: int, dy: int, count: int\n",
    ") -> Image.Image:\n",
    "    \"\"\"\n",
    "    Draw 'count' filled triangles pointing (dx, dy) on the given RGBA image.\n",
    "    Triangles are centered: the centroid of each triangle is symmetrically arranged\n",
    "    around the image center. Spacing is between triangle centroids.\n",
    "    \"\"\"\n",
    "    if count <= 0 or (dx, dy) == (0, 0):\n",
    "        return image\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "    cx, cy = size // 2, size // 2\n",
    "\n",
    "    # Triangle geometry (relative to size)\n",
    "    tri_height = max(4, int(size * 0.16))\n",
    "    tri_half_base = max(3, int(size * 0.10))\n",
    "    spacing = max(2, int(size * 0.12))  # distance between triangle centroids\n",
    "\n",
    "    # Axis-aligned direction and perpendicular\n",
    "    ux, uy = dx, dy  # points toward the triangle tip\n",
    "    px, py = -uy, ux  # perpendicular (for base width)\n",
    "\n",
    "    # Offsets for centroids: 1 -> [0], 2 -> [-0.5s, +0.5s], 3 -> [-s, 0, +s], ...\n",
    "    offsets = [(i - (count - 1) / 2.0) * spacing for i in range(count)]\n",
    "\n",
    "    # For an isosceles triangle, the centroid lies 1/3 of the height from the base toward the tip.\n",
    "    # If C is the centroid, then:\n",
    "    #   tip = C + (2/3)*tri_height * u\n",
    "    #   base_center = C - (1/3)*tri_height * u\n",
    "    tip_offset = (2.0 / 3.0) * tri_height\n",
    "    base_offset = (1.0 / 3.0) * tri_height\n",
    "\n",
    "    for off in offsets:\n",
    "        # Centroid position\n",
    "        Cx = cx + int(round(ux * off))\n",
    "        Cy = cy + int(round(uy * off))\n",
    "\n",
    "        # Tip and base-center positions\n",
    "        tip_x = int(round(Cx + ux * tip_offset))\n",
    "        tip_y = int(round(Cy + uy * tip_offset))\n",
    "        base_x = int(round(Cx - ux * base_offset))\n",
    "        base_y = int(round(Cy - uy * base_offset))\n",
    "\n",
    "        # Base vertices around base center along the perpendicular\n",
    "        p1 = (tip_x, tip_y)\n",
    "        p2 = (\n",
    "            int(round(base_x + px * tri_half_base)),\n",
    "            int(round(base_y + py * tri_half_base)),\n",
    "        )\n",
    "        p3 = (\n",
    "            int(round(base_x - px * tri_half_base)),\n",
    "            int(round(base_y - py * tri_half_base)),\n",
    "        )\n",
    "\n",
    "        draw.polygon([p1, p2, p3], fill=(255, 255, 255, 220), outline=(0, 0, 0, 220))\n",
    "\n",
    "    return image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "29a74244",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['boots', 'box', 'coin', 'exit', 'floor', 'gem', 'ghost', 'human', 'key', 'lava', 'locked', 'metalbox', 'opened', 'portal', 'robot', 'shield', 'sleeping', 'spike', 'wall', 'wolf', 'dragon']\n",
    "\n",
    "ASSET_DIR = \"../data/assets/imagen1\"\n",
    "class RandomDirection:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __call__(self, image: Image.Image, label: int):\n",
    "        # make image overlay with a background\n",
    "        if labels[label] != 'floor':\n",
    "            floor_dir = os.path.join(ASSET_DIR, \"floor\")\n",
    "            floor_files = [\n",
    "                f for f in os.listdir(floor_dir)\n",
    "                if f.lower().endswith((\".png\"))\n",
    "            ]\n",
    "\n",
    "            if len(floor_files) > 0:\n",
    "                fname = random.choice(floor_files)\n",
    "                floor_path = os.path.join(floor_dir, fname)\n",
    "                with open(floor_path, \"rb\") as f:\n",
    "                    floor_img = Image.open(f).convert(\"RGBA\")\n",
    "\n",
    "                if floor_img.size != image.size:\n",
    "                    floor_img = floor_img.resize(image.size)\n",
    "\n",
    "                bg = floor_img.copy()\n",
    "                bg.paste(image, (0, 0), image)\n",
    "                image = bg\n",
    "\n",
    "        if labels[label] == 'box' or labels[label] == 'metalbox' or labels[label] == 'robot':\n",
    "            directions = [(1, 0), (-1, 0), (0, 1), (0, -1)]\n",
    "            random.seed(time.time())\n",
    "            decision = random.randint(-1, 3)\n",
    "\n",
    "            if decision < 0:\n",
    "                return image\n",
    "\n",
    "            dx, dy = directions[decision]\n",
    "            new_image: Image.Image = draw_direction_triangles_on_image(image=image, size=image.size[0], dx=dx, dy=dy, count=1)       \n",
    "\n",
    "            return new_image\n",
    "        return  image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1a268974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset, transform):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.random_direction = RandomDirection()\n",
    "        self.targets = base_dataset.targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.base_dataset[idx]\n",
    "        new_image = self.random_direction(image, label)\n",
    "        image = self.transform(new_image)\n",
    "        return image, label\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894cf1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARTS TAKEN FROM CHATGPT, conversation link: https://chatgpt.com/share/69115bb7-ae24-8008-a13d-26cafe249446 . PLEASE SCROLL TO THE BOTTOM\n",
    "\n",
    "def get_augmentations():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize(64),\n",
    "        transforms.CenterCrop(48),\n",
    "        transforms.ColorJitter(\n",
    "            brightness=0.3,\n",
    "            contrast=0.5,\n",
    "            saturation=0.3,\n",
    "            hue=0.02,\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9413d639",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSET_DIR = \"../data/assets/imagen1\"\n",
    "\n",
    "def rgba_loader(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        img = Image.open(f)\n",
    "        return img.convert(\"RGBA\") \n",
    "\n",
    "base_dataset = ImageFolder(root=ASSET_DIR, loader=rgba_loader)\n",
    "dataset = CustomDataset(base_dataset, transform=get_augmentations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5c3327ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RGBA'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset[0][0].mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec93552a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boots': 0,\n",
       " 'box': 1,\n",
       " 'coin': 2,\n",
       " 'exit': 3,\n",
       " 'floor': 4,\n",
       " 'gem': 5,\n",
       " 'ghost': 6,\n",
       " 'human': 7,\n",
       " 'key': 8,\n",
       " 'lava': 9,\n",
       " 'locked': 10,\n",
       " 'metalbox': 11,\n",
       " 'opened': 12,\n",
       " 'portal': 13,\n",
       " 'robot': 14,\n",
       " 'shield': 15,\n",
       " 'sleeping': 16,\n",
       " 'spike': 17,\n",
       " 'wall': 18}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "567b9bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = dataset.targets\n",
    "indices = list(range(len(targets)))\n",
    "\n",
    "train_idx, test_idx = train_test_split(\n",
    "    indices,\n",
    "    test_size=0.4,\n",
    "    random_state=int(time.time())\n",
    ")\n",
    "\n",
    "train_data = Subset(dataset, train_idx)\n",
    "test_data = Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dc77d01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=256, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0d2e519a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5374f4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(pred: torch.Tensor, label: torch.Tensor) -> torch.Tensor:\n",
    "    y_pred = torch.argmax(pred, dim=1).long()\n",
    "    label = label.view(-1).long() \n",
    "    return (y_pred == label).float().mean()\n",
    "\n",
    "def get_model_accuracy(model: nn.Module):\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "\n",
    "        sum_acc = 0\n",
    "        cnt = 0\n",
    "\n",
    "        for x, y in test_loader:\n",
    "            pred = model(x)\n",
    "\n",
    "            sum_acc += get_accuracy(pred, y)\n",
    "            cnt += 1\n",
    "        \n",
    "        return float(sum_acc / cnt)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "427186cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(loader: torch.utils.data.DataLoader, model: nn.Module):\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    optimiser = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    loss_fn = nn.CrossEntropyLoss()  \n",
    "\n",
    "    epoch_losses = []\n",
    "    for i in range(50):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "        for _, (x, y) in enumerate(loader):\n",
    "            optimiser.zero_grad()\n",
    "            # x, y = x.cuda(), y.cuda()\n",
    "            y_pred = model(x)\n",
    "            \n",
    "            loss = loss_fn(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "        epoch_loss = epoch_loss / len(loader)\n",
    "        epoch_losses.append(epoch_loss)\n",
    "        print(\"Epoch: {}, Loss: {}, Accuracy: {}\".format(i, epoch_loss, get_model_accuracy(model)))\n",
    "        \n",
    "\n",
    "    return model, epoch_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d658bc7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.906214714050293, Accuracy: 0.10497237741947174\n",
      "Epoch: 1, Loss: 2.081867814064026, Accuracy: 0.14364640414714813\n",
      "Epoch: 2, Loss: 1.5715546607971191, Accuracy: 0.24861878156661987\n",
      "Epoch: 3, Loss: 1.3893590569496155, Accuracy: 0.22651933133602142\n",
      "Epoch: 4, Loss: 1.134418249130249, Accuracy: 0.23204420506954193\n",
      "Epoch: 5, Loss: 0.8313997089862823, Accuracy: 0.20994475483894348\n",
      "Epoch: 6, Loss: 0.6465904116630554, Accuracy: 0.24309392273426056\n",
      "Epoch: 7, Loss: 0.6601065993309021, Accuracy: 0.27624309062957764\n",
      "Epoch: 8, Loss: 0.4334820806980133, Accuracy: 0.2983425557613373\n",
      "Epoch: 9, Loss: 0.591965064406395, Accuracy: 0.33701658248901367\n",
      "Epoch: 10, Loss: 0.25143951177597046, Accuracy: 0.45303866267204285\n",
      "Epoch: 11, Loss: 0.3218632936477661, Accuracy: 0.5138121843338013\n",
      "Epoch: 12, Loss: 0.34115029871463776, Accuracy: 0.6353591084480286\n",
      "Epoch: 13, Loss: 0.2238486409187317, Accuracy: 0.6629834175109863\n",
      "Epoch: 14, Loss: 0.21913491934537888, Accuracy: 0.7513812184333801\n",
      "Epoch: 15, Loss: 0.19227968156337738, Accuracy: 0.7900552749633789\n",
      "Epoch: 16, Loss: 0.1121678501367569, Accuracy: 0.7790055274963379\n",
      "Epoch: 17, Loss: 0.21583108603954315, Accuracy: 0.8011049628257751\n",
      "Epoch: 18, Loss: 0.08008311036974192, Accuracy: 0.8729282021522522\n",
      "Epoch: 19, Loss: 0.14476296305656433, Accuracy: 0.8618784546852112\n",
      "Epoch: 20, Loss: 0.0684780403971672, Accuracy: 0.8508287072181702\n",
      "Epoch: 21, Loss: 0.06653054244816303, Accuracy: 0.8397790193557739\n",
      "Epoch: 22, Loss: 0.06540710851550102, Accuracy: 0.8453038930892944\n",
      "Epoch: 23, Loss: 0.07942861318588257, Accuracy: 0.8618784546852112\n",
      "Epoch: 24, Loss: 0.03651362378150225, Accuracy: 0.8618784546852112\n",
      "Epoch: 25, Loss: 0.029717994388192892, Accuracy: 0.8674033284187317\n",
      "Epoch: 26, Loss: 0.035069892182946205, Accuracy: 0.8839778900146484\n",
      "Epoch: 27, Loss: 0.04017365910112858, Accuracy: 0.9060773253440857\n",
      "Epoch: 28, Loss: 0.019774149172008038, Accuracy: 0.8839778900146484\n",
      "Epoch: 29, Loss: 0.069210609421134, Accuracy: 0.8729282021522522\n",
      "Epoch: 30, Loss: 0.05271269101649523, Accuracy: 0.8729282021522522\n",
      "Epoch: 31, Loss: 0.017096804454922676, Accuracy: 0.8618784546852112\n",
      "Epoch: 32, Loss: 0.01518403203226626, Accuracy: 0.8066298365592957\n",
      "Epoch: 33, Loss: 0.05173720791935921, Accuracy: 0.8397790193557739\n",
      "Epoch: 34, Loss: 0.02852335898205638, Accuracy: 0.8397790193557739\n",
      "Epoch: 35, Loss: 0.020214632153511047, Accuracy: 0.8618784546852112\n",
      "Epoch: 36, Loss: 0.07725499663501978, Accuracy: 0.90055251121521\n",
      "Epoch: 37, Loss: 0.047871765680611134, Accuracy: 0.9337016344070435\n",
      "Epoch: 38, Loss: 0.029058709740638733, Accuracy: 0.9281768202781677\n",
      "Epoch: 39, Loss: 0.08792273513972759, Accuracy: 0.9558011293411255\n",
      "Epoch: 40, Loss: 0.01686577871441841, Accuracy: 0.9447513818740845\n",
      "Epoch: 41, Loss: 0.06309554353356361, Accuracy: 0.939226508140564\n",
      "Epoch: 42, Loss: 0.017323559150099754, Accuracy: 0.9171270728111267\n",
      "Epoch: 43, Loss: 0.019181882264092565, Accuracy: 0.9171270728111267\n",
      "Epoch: 44, Loss: 0.097184207290411, Accuracy: 0.9281768202781677\n",
      "Epoch: 45, Loss: 0.04223131015896797, Accuracy: 0.9447513818740845\n",
      "Epoch: 46, Loss: 0.028373348526656628, Accuracy: 0.9779005646705627\n",
      "Epoch: 47, Loss: 0.047942301258444786, Accuracy: 0.9779005646705627\n",
      "Epoch: 48, Loss: 0.013234561774879694, Accuracy: 0.9558011293411255\n",
      "Epoch: 49, Loss: 0.033077994361519814, Accuracy: 0.9613259434700012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Conv2d(4, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (1): LeakyReLU(negative_slope=0.1)\n",
       "   (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "   (5): LeakyReLU(negative_slope=0.1)\n",
       "   (6): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (8): Flatten(start_dim=1, end_dim=-1)\n",
       "   (9): Linear(in_features=2304, out_features=64, bias=True)\n",
       "   (10): LeakyReLU(negative_slope=0.1)\n",
       "   (11): Linear(in_features=64, out_features=21, bias=True)\n",
       " ),\n",
       " [2.906214714050293,\n",
       "  2.081867814064026,\n",
       "  1.5715546607971191,\n",
       "  1.3893590569496155,\n",
       "  1.134418249130249,\n",
       "  0.8313997089862823,\n",
       "  0.6465904116630554,\n",
       "  0.6601065993309021,\n",
       "  0.4334820806980133,\n",
       "  0.591965064406395,\n",
       "  0.25143951177597046,\n",
       "  0.3218632936477661,\n",
       "  0.34115029871463776,\n",
       "  0.2238486409187317,\n",
       "  0.21913491934537888,\n",
       "  0.19227968156337738,\n",
       "  0.1121678501367569,\n",
       "  0.21583108603954315,\n",
       "  0.08008311036974192,\n",
       "  0.14476296305656433,\n",
       "  0.0684780403971672,\n",
       "  0.06653054244816303,\n",
       "  0.06540710851550102,\n",
       "  0.07942861318588257,\n",
       "  0.03651362378150225,\n",
       "  0.029717994388192892,\n",
       "  0.035069892182946205,\n",
       "  0.04017365910112858,\n",
       "  0.019774149172008038,\n",
       "  0.069210609421134,\n",
       "  0.05271269101649523,\n",
       "  0.017096804454922676,\n",
       "  0.01518403203226626,\n",
       "  0.05173720791935921,\n",
       "  0.02852335898205638,\n",
       "  0.020214632153511047,\n",
       "  0.07725499663501978,\n",
       "  0.047871765680611134,\n",
       "  0.029058709740638733,\n",
       "  0.08792273513972759,\n",
       "  0.01686577871441841,\n",
       "  0.06309554353356361,\n",
       "  0.017323559150099754,\n",
       "  0.019181882264092565,\n",
       "  0.097184207290411,\n",
       "  0.04223131015896797,\n",
       "  0.028373348526656628,\n",
       "  0.047942301258444786,\n",
       "  0.013234561774879694,\n",
       "  0.033077994361519814])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(21)\n",
    "train_model(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "01331bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9668508172035217"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_accuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cee52500",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"image_models/crop-center\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "bae4ab9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WRONG LABEL, expected: 13, got: 4\n",
      "WRONG LABEL, expected: 10, got: 16\n",
      "WRONG LABEL, expected: 10, got: 18\n",
      "WRONG LABEL, expected: 14, got: 7\n",
      "WRONG LABEL, expected: 15, got: 7\n",
      "WRONG LABEL, expected: 6, got: 17\n",
      "WRONG LABEL, expected: 10, got: 16\n",
      "Total count: 13, label: 0, Accuracy: 1.0\n",
      "Total count: 7, label: 1, Accuracy: 1.0\n",
      "Total count: 13, label: 2, Accuracy: 1.0\n",
      "Total count: 8, label: 3, Accuracy: 1.0\n",
      "Total count: 8, label: 4, Accuracy: 1.0\n",
      "Total count: 10, label: 5, Accuracy: 1.0\n",
      "Total count: 7, label: 6, Accuracy: 0.8571428571428571\n",
      "Total count: 13, label: 7, Accuracy: 1.0\n",
      "Total count: 9, label: 8, Accuracy: 1.0\n",
      "Total count: 11, label: 9, Accuracy: 1.0\n",
      "Total count: 7, label: 10, Accuracy: 0.5714285714285714\n",
      "Total count: 13, label: 11, Accuracy: 1.0\n",
      "Total count: 10, label: 12, Accuracy: 1.0\n",
      "Total count: 8, label: 13, Accuracy: 0.875\n",
      "Total count: 10, label: 14, Accuracy: 0.9\n",
      "Total count: 10, label: 15, Accuracy: 0.9\n",
      "Total count: 7, label: 16, Accuracy: 1.0\n",
      "Total count: 8, label: 17, Accuracy: 1.0\n",
      "Total count: 9, label: 18, Accuracy: 1.0\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mZeroDivisionError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     23\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m21\u001b[39m):\n\u001b[32m     24\u001b[39m                 \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTotal count: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, label: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, Accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(cnt[i], i, \u001b[38;5;28mfloat\u001b[39m(acc[i] / cnt[i])))\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[43mget_accuracy_for_each_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[104]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mget_accuracy_for_each_label\u001b[39m\u001b[34m(model)\u001b[39m\n\u001b[32m     21\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWRONG LABEL, expected: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, got: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(label[i], y_pred[i]))\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m21\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTotal count: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, label: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m, Accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(cnt[i], i, \u001b[38;5;28mfloat\u001b[39m(\u001b[43macc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mcnt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)))\n",
      "\u001b[31mZeroDivisionError\u001b[39m: division by zero"
     ]
    }
   ],
   "source": [
    "def get_accuracy_for_each_label(model: nn.Module):\n",
    "    for epoch in range(0, 3):\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            \n",
    "            acc: List[int] = [0 for i in range(21)]\n",
    "            cnt: List[int] = [0 for i in range(21)]\n",
    "\n",
    "            for x, y in test_loader:\n",
    "                for label in y:\n",
    "                    cnt[label] += 1\n",
    "                \n",
    "                pred = model(x)\n",
    "                y_pred = torch.argmax(pred, dim=1).long()\n",
    "                label = y.view(-1).long()\n",
    "\n",
    "                for i in range(len(y_pred)):\n",
    "                    if y_pred[i] == label[i]:\n",
    "                        acc[label[i]] += 1\n",
    "                    else:\n",
    "                        print(\"WRONG LABEL, expected: {}, got: {}\".format(label[i], y_pred[i]))\n",
    "\n",
    "            for i in range(21):\n",
    "                print(\"Total count: {}, label: {}, Accuracy: {}\".format(cnt[i], i, float(acc[i] / cnt[i])))\n",
    "\n",
    "get_accuracy_for_each_label(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7f94d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model(21)\n",
    "model.load_state_dict(torch.load(\"image_models/crop-center\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da8be678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autoâ€‘generate a loader snippet for the trained PyTorch model\n",
    "from utils import generate_torch_loader_snippet\n",
    "\n",
    "example_input = torch.tensor(\n",
    "    [[0.0, 0.0]], dtype=torch.float32\n",
    ")  # minimal example for tracing if needed\n",
    "snippet = generate_torch_loader_snippet(\n",
    "    model=model, prefer=\"auto\"\n",
    ", compression=\"zlib\")\n",
    "\n",
    "with open(\"exported_models/image_model.py\", \"w\") as f:\n",
    "    f.write(snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9d8558",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs2109s-ay2526s1-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
